.. _01_stage_data.py:

=============
01_stage_data.py
=============

::

    # Copyright 2018 The SQLNet Company GmbH

    # Permission is hereby granted, free of charge, to any person obtaining a copy
    # of this software and associated documentation files (the "Software"), to
    # deal in the Software without restriction, including without limitation the
    # rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
    # sell copies of the Software, and to permit persons to whom the Software is
    # furnished to do so, subject to the following conditions:

    # The above copyright notice and this permission notice shall be included in
    # all copies or substantial portions of the Software.

    # THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
    # FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
    # DEALINGS IN THE SOFTWARE.

    import datetime
    import os

    import numpy as np
    import pandas as pd

    import autosql.engine as engine

    # -----------------------------------------------------------------------------
    # Set up folders - you need to insert folders on your computer

    # The folder that contains expd151.csv
    RAW_DATA_FOLDER = "/home/patrick/Consumer Expenditure Survey/Data/"

    # -----------------------------------------------------------------------------

    engine.set_project("PUMD Expenditure")

    # -----------------------------------------------------------------------------
    # Read the data from the source files

    os.chdir(RAW_DATA_FOLDER)

    expd = pd.read_csv("expd151.csv")
    expd = expd.append(pd.read_csv("expd152.csv"))
    expd = expd.append(pd.read_csv("expd153.csv"))
    expd = expd.append(pd.read_csv("expd154.csv"))

    # -----------------------------------------------------------------------------
    # Set up target - we want to predict whether the item is a gift

    expd["TARGET"] = [0.0 if elem == 2 else 1.0 for elem in expd["GIFT"]]

    # -----------------------------------------------------------------------------
    # Remove the instances where date is nan - they will be ignored by the AutoSQL
    # engine anyway, because of the NULL value handling policy.

    expd = expd[
        (expd["EXPNYR"] == expd["EXPNYR"]) & (expd["EXPNMO"] == expd["EXPNMO"])
    ]

    # -----------------------------------------------------------------------------
    # Set up date - TIME_STAMP_SHIFTED exists to make sure only data up to the
    # PREVIOUS month is used.

    expd["TIME_STAMP"] = [
        datetime.datetime(int(year), int(month), 1) for year, month in zip(expd["EXPNYR"], expd["EXPNMO"])
    ]

    expd["TIME_STAMP_SHIFTED"] = [
        datetime.datetime(int(year), int(month), 15) for year, month in zip(expd["EXPNYR"], expd["EXPNMO"])
    ]

    # -----------------------------------------------------------------------------
    # Set up "BASKETID"

    expd["BASKETID"] = [
        str(x) + "_" + y.strftime("%Y-%m") for x, y in zip(expd["NEWID"], expd["TIME_STAMP"])
    ]

    # -----------------------------------------------------------------------------
    # Build a training, validation and testing flag. We will use January to August
    # for training, September and October for validation and November and December
    # for testing. If you decide to add more data, you should probably come up
    # with your own way of separating the data.

    expd["TrainValTest"] = [
        "Testing" if month > 10.0 else
        "Validation" if month > 8.0 else
        "Training" for month in expd["EXPNMO"]
    ]

    # -----------------------------------------------------------------------------
    # Set up UCCs - the UCCs are a way to systematically categorize products.
    # Every digit has significance. That is why we create extra columns for
    # that contain the first digit, the first two digits etc.

    ucc = np.asarray(expd["UCC"]).astype(str)

    expd["UCC1"] = [elem[:1] for elem in ucc]
    expd["UCC2"] = [elem[:2] for elem in ucc]
    expd["UCC3"] = [elem[:3] for elem in ucc]
    expd["UCC4"] = [elem[:4] for elem in ucc]
    expd["UCC5"] = [elem[:5] for elem in ucc]

    # -----------------------------------------------------------------------------
    # Set up units - this allows the engine to directly compare

    units = dict()

    units["UCC"] = "UCC"
    units["UCC1"] = "UCC1"
    units["UCC2"] = "UCC2"
    units["UCC3"] = "UCC3"
    units["UCC4"] = "UCC4"
    units["UCC5"] = "UCC5"

    # Adding 'comparison only' to the unit
    # forces AutoSQL to always compare this
    # column to others.
    units["EXPNYR"] = "year, comparison only"

    # -----------------------------------------------------------------------------
    # Declare CATEGORICAL, DISCRETE, JOIN_KEYS, NUMERICAL, TARGETS, TIME_STAMPS

    CATEGORICAL = [
        "UCC",
        "UCC1",
        "UCC2",
        "UCC3",
        "UCC4",
        "UCC5"
    ]

    DISCRETE = [
        "EXPNYR"
    ]

    JOIN_KEYS = [
        "NEWID",
        "BASKETID"
    ]

    NUMERICAL = [
        "COST"
    ]

    TARGETS = [
        "TARGET"
    ]

    TIME_STAMPS = [
        "TIME_STAMP",
        "TIME_STAMP_SHIFTED"
    ]

    # -----------------------------------------------------------------------------
    # Prepare tables and store in folder. Only the population table needs to be split
    # into a training, validation and testing set. The peripheral tables can be stored as whole.
    # The condition t2.TIME_STAMP <= t1.TIME_STAMP will ensure that there are no
    # easter eggs.

    expd_training = engine.DataFrame(
        "EXPD_TRAINING",
        join_keys=JOIN_KEYS,
        time_stamps=TIME_STAMPS,
        categorical=CATEGORICAL,
        discrete=DISCRETE,
        numerical=NUMERICAL,
        targets=TARGETS,
        units=units
    ).send(
        expd[expd["TrainValTest"] == "Training"]
    )

    expd_training.save()

    expd_validation = engine.DataFrame(
        "EXPD_VALIDATION",
        join_keys=JOIN_KEYS,
        time_stamps=TIME_STAMPS,
        categorical=CATEGORICAL,
        discrete=DISCRETE,
        numerical=NUMERICAL,
        targets=TARGETS,
        units=units
    ).send(
        expd[expd["TrainValTest"] == "Validation"]
    )

    expd_validation.save()

    expd_testing = engine.DataFrame(
        "EXPD_TESTING",
        join_keys=JOIN_KEYS,
        time_stamps=TIME_STAMPS,
        categorical=CATEGORICAL,
        discrete=DISCRETE,
        numerical=NUMERICAL,
        targets=TARGETS,
        units=units
    ).send(
        expd[expd["TrainValTest"] == "Testing"]
    )

    expd_testing.save()

    # -----------------------------------------------------------------------------
    # The peripheral table simply contains the entire dataset.

    expd_all = engine.DataFrame(
        "EXPD",
        join_keys=JOIN_KEYS,
        time_stamps=TIME_STAMPS,
        categorical=CATEGORICAL,
        discrete=DISCRETE,
        numerical=NUMERICAL,
        targets=TARGETS,
        units=units
    ).send(expd)

    expd_all.save()
