.. _example_07_null_values.py:

=============
example_07_null_values.py
=============

::

    # Copyright 2018 The SQLNet Company GmbH

    # Permission is hereby granted, free of charge, to any person obtaining a copy
    # of this software and associated documentation files (the "Software"), to
    # deal in the Software without restriction, including without limitation the
    # rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
    # sell copies of the Software, and to permit persons to whom the Software is
    # furnished to do so, subject to the following conditions:

    # The above copyright notice and this permission notice shall be included in
    # all copies or substantial portions of the Software.

    # THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
    # FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
    # DEALINGS IN THE SOFTWARE.

    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    import scipy.stats
    import sklearn.linear_model as linear_model

    import autosql.aggregations as aggregations
    import autosql.engine as engine
    import autosql.loss_functions as loss_functions
    import autosql.models as models

    #----------------

    engine.set_project("examples")

    #----------------
    # Generate artificial dataset
    # The problem we create looks like this:
    #
    # AVG( t2.column_01 ) AS target
    # FROM POPULATION t1
    # LEFT JOIN PERIPHERAL t2
    # ON t1.join_key = t2.join_key
    # WHERE t2.column_01 > 0
    # AND t2.time_stamp  <= t1.time_stamp
    # GROUP BY t2.join_key;

    # Don't worry - you don't really have to understand this part.
    # This is just how we generate the example dataset. To learn more
    # about AutoSQL just skip to "Build data model".

    population_table = np.random.rand(500, 2).astype(np.float64)

    join_keys_perip = []
    num_elements_in_sample = []
    for i in range(500):
        j = int(500.0 * np.random.rand(1)[0])
        join_keys_perip += [i] * j
        num_elements_in_sample += [float(j)]

    join_keys_perip = np.asarray(join_keys_perip)

    num_elements_in_sample = np.asarray(num_elements_in_sample).reshape(500, 1)

    population = (np.random.rand(500, 1) * 2.0 - 1.0).astype(np.float64)

    time_stamps_popul = (np.random.rand(500, 1) * 2.0 -
                     1.0).astype(np.float64).ravel()

    peripheral = (np.random.rand(len(join_keys_perip), 1)
              * 2.0 - 1.0).astype(np.float64)

    time_stamps_perip = (np.random.rand(len(join_keys_perip), 1)
                     * 2.0 - 1.0).astype(np.float64).ravel()

    # Randomly assign nan to 10% of peripheral
    peripheral = np.asarray([
        float("nan") if np.random.rand(1)[0] < 0.1 else p for p in peripheral
    ]).astype(np.float64).ravel()

    # Randomly assign nan to 10% of time_stamps_perip
    time_stamps_perip = np.asarray([
        float("nan") if np.random.rand(1)[0] < 0.1 else tsp for tsp in time_stamps_perip
    ]).astype(np.float64).ravel()

    # Randomly assign nan to 10% of join keys
    join_keys_popul = np.arange(500)

    join_keys_popul = np.asarray([
        "" if np.random.rand(1)[0] < 0.1 else jk for jk in join_keys_popul
    ]).ravel()


    cumulative_num_elements = np.asarray(
        [0] + np.cumsum(num_elements_in_sample).tolist()
    )

    # Targets are the number of times where an element peripheral is
    # smaller than the corresponding element in population,
    # but greater or equal to the corresponding element - 0.5
    targets = []
    for i in range(500):
        #
        if join_keys_popul[i] == "":
        targets.append(0.0)
        continue
        #
        tsi = time_stamps_perip[
        int(cumulative_num_elements[i]):int(cumulative_num_elements[i + 1])
        ]
        #
        p = peripheral[
        int(cumulative_num_elements[i]):int(cumulative_num_elements[i + 1])
        ]
        #
        p = p[
        (tsi.ravel() < time_stamps_popul[i])
        & (p > 0.0)
        ]
        if (len(p) == 0):
        targets.append(0.0)
        else:
        targets.append(p.mean())

    targets = np.asarray(targets).reshape(500, 1).astype(np.float64)

    # -----------------------
    # To pandas.DataFrames

    peripheral_table = pd.DataFrame()
    peripheral_table["column_01"] = peripheral.ravel()
    peripheral_table["join_key"] = join_keys_perip.ravel()
    peripheral_table["time_stamp"] = time_stamps_perip.ravel()

    population_table = pd.DataFrame()
    population_table["column_01"] = population.ravel()
    population_table["join_key"] = join_keys_popul.ravel()
    population_table["time_stamp"] = time_stamps_popul.ravel()
    population_table["targets"] = targets.ravel()

    # ----------------
    # Build data model

    population_placeholder = models.Placeholder(
        name="POPULATION",
        join_keys=["join_key"],
        time_stamps=["time_stamp"],
        targets=["targets"]
    )

    peripheral_placeholder = models.Placeholder(
        name="PERIPHERAL",
        join_keys=["join_key"],
        time_stamps=["time_stamp"]
    )

    population_placeholder.join(peripheral_placeholder, "join_key", "time_stamp")

    model = models.Model(
        population=population_placeholder,
        peripheral=[peripheral_placeholder],
        predictor=linear_model.LinearRegression(),
        loss_function=loss_functions.SquareLoss(),
        aggregation=[aggregations.Count(), aggregations.Sum(), aggregations.Avg()],
        use_timestamps=True,
        num_features=10,
        max_length=1,
        fast_training=False,
        min_num_samples=200,
        shrinkage=0.0,
        grid_factor=1.0,
        share_aggregations=1.0
    ).send()

    model = model.fit(
        population_table=population_table,
        peripheral_tables=[peripheral_table]
    )

    features = model.transform(
        population_table=population_table,
        peripheral_tables=[peripheral_table]
    )

    yhat = model.predict(
        population_table=population_table,
        peripheral_tables=[peripheral_table]
    )

    print(model.to_sql())

    plt.grid(True)
    plt.xlabel("targets")
    plt.ylabel("predictions")
    plt.scatter(targets.ravel(), features[:, 0])
    plt.show()

    plt.grid(True)
    plt.xlabel("targets")
    plt.ylabel("predictions")
    plt.scatter(targets.ravel(), features.mean(axis=1))
    plt.show()

    plt.grid(True)
    plt.xlabel("targets")
    plt.ylabel("predictions")
    plt.scatter(targets.ravel(), yhat.ravel())
    plt.show()
